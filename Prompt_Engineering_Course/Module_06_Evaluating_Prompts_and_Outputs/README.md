# Module 06: Evaluating Prompts and Outputs

## Learning Outcomes

Upon completing this module, you will be able to:

*   Define key metrics for evaluating LLM outputs.
*   Identify and mitigate common LLM issues such as hallucinations and bias.
*   Implement iterative prompt refinement strategies.
*   Understand the principles of A/B testing for prompts.

## Prerequisites

*   Completion of Module 05: Prompt Chaining and Workflows.
*   Familiarity with designing and implementing prompt workflows.

## Usage Instructions

1.  Read `notes.md` to learn about the critical process of evaluating LLM performance and refining prompts.
2.  Work through the exercises in the `exercises/` directory to gain practical experience in assessing outputs and improving prompt effectiveness.

## Module Content

*   `notes.md`: Detailed explanations of evaluation metrics, common LLM issues, iterative refinement, and A/B testing.
*   `exercises/evaluation_exercises.md`: Hands-on exercises for evaluating and improving prompts and outputs.


